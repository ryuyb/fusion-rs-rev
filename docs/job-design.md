# å®šæ—¶ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿå®æ–½è®¡åˆ’

## æ¦‚è¿°

åœ¨ fusion-rs é¡¹ç›®ä¸­å®ç°åŸºäº **apalis** çš„å®šæ—¶ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼Œæ”¯æŒ Cron è¡¨è¾¾å¼ã€åŠ¨æ€ç®¡ç†ã€å¤±è´¥é‡è¯•ã€å†å²è®°å½•å’Œå‘Šè­¦é€šçŸ¥ã€‚

## ç”¨æˆ·éœ€æ±‚æ€»ç»“

- âœ… **åŠŸèƒ½èŒƒå›´**ï¼šè°ƒåº¦å™¨æ¡†æ¶ + ç¤ºä¾‹ä»»åŠ¡ï¼ˆæ•°æ®æ¸…ç†ï¼‰
- âœ… **å¤±è´¥å¤„ç†**ï¼šæ—¥å¿—è®°å½• + è‡ªåŠ¨é‡è¯• + æ‰§è¡Œå†å² + å‘Šè­¦é€šçŸ¥
- âœ… **ç®¡ç†æ–¹å¼**ï¼šæ”¯æŒè¿è¡Œæ—¶åŠ¨æ€ç®¡ç†ï¼ˆAPIï¼‰
- âœ… **æŠ€æœ¯é€‰å‹**ï¼šapalis ä»»åŠ¡é˜Ÿåˆ—åº“
- âœ… **é…ç½®éœ€æ±‚**ï¼šå¯ç”¨å¼€å…³ã€Cron è¡¨è¾¾å¼ã€å…¨å±€å¹¶å‘æ•°é‡
- âœ… **ä»»åŠ¡çº§å¹¶å‘æ§åˆ¶**ï¼šæ¯ä¸ªä»»åŠ¡å¯é…ç½®æ˜¯å¦å…è®¸å¹¶è¡Œè¿è¡Œæˆ–æœ€å¤§å¹¶è¡Œæ•°é‡

---

## æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

- **apalis (v1.0.0-beta.2)** - ä»»åŠ¡é˜Ÿåˆ—æ ¸å¿ƒåº“
- **apalis-sql (v1.0.0-beta.2)** - PostgreSQL åç«¯å­˜å‚¨
- **cron (v0.13)** - Cron è¡¨è¾¾å¼è§£æå’ŒéªŒè¯
- **diesel + diesel-async** - å¤ç”¨ç°æœ‰æ•°æ®åº“è¿æ¥æ± 

### é€‰å‹ç†ç”±

1. **PostgreSQL åç«¯**ï¼šå¤ç”¨ç°æœ‰åŸºç¡€è®¾æ–½ï¼Œæ— éœ€ Redis
2. **apalis ç”Ÿæ€**ï¼šæˆç†Ÿçš„ Rust ä»»åŠ¡é˜Ÿåˆ—ï¼Œæ”¯æŒåˆ†å¸ƒå¼
3. **æŒä¹…åŒ–**ï¼šä»»åŠ¡é…ç½®å’Œå†å²å­˜å‚¨åœ¨æ•°æ®åº“ï¼ŒæœåŠ¡é‡å¯ä¸ä¸¢å¤±
4. **å†…ç½®åŠŸèƒ½ä¸°å¯Œ**ï¼š
   - âœ… æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥
   - âœ… ä»»åŠ¡è¶…æ—¶å¤„ç†
   - âœ… ä¼˜é›…å…³é—­æœºåˆ¶
   - âœ… Prometheus ç›‘æ§é›†æˆ
   - âœ… Worker çº§å¹¶å‘æ§åˆ¶
   - âœ… ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ç›‘å¬

---

## å®æ–½æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è®¾æ–½ï¼ˆä¼˜å…ˆçº§ï¼šP0ï¼‰

#### 1. æ·»åŠ ä¾èµ–

**æ–‡ä»¶ï¼š`Cargo.toml`**

```toml
[dependencies]
# ä»»åŠ¡è°ƒåº¦æ ¸å¿ƒ
apalis = { version = "1.0.0-beta.2", features = ["limit", "tracing"] }
apalis-sql = { version = "1.0.0-beta.2", features = ["postgres", "tokio-comp"] }
cron = "0.13"

# ç›‘æ§(å¯é€‰)
metrics-exporter-prometheus = "0.15"
```

#### 2. æ•°æ®åº“ Schema

**åˆ›å»ºæ–‡ä»¶ï¼š`migrations/{timestamp}_create_jobs_tables/up.sql`**

æ ¸å¿ƒè¡¨è®¾è®¡ï¼š

```sql
-- ä»»åŠ¡å®šä¹‰è¡¨
CREATE TABLE jobs (
    id SERIAL PRIMARY KEY,
    job_name VARCHAR(255) NOT NULL UNIQUE,
    job_type VARCHAR(100) NOT NULL,
    cron_expression VARCHAR(255),
    enabled BOOLEAN NOT NULL DEFAULT true,

    -- å¹¶å‘æ§åˆ¶ï¼ˆæ–°å¢ï¼‰
    allow_concurrent BOOLEAN NOT NULL DEFAULT false,
    max_concurrent INTEGER, -- NULL è¡¨ç¤ºæ— é™åˆ¶

    max_retries INTEGER NOT NULL DEFAULT 3,
    retry_delay_seconds INTEGER NOT NULL DEFAULT 60,
    timeout_seconds INTEGER NOT NULL DEFAULT 300,
    payload JSONB,
    last_run_at TIMESTAMP,
    last_run_status VARCHAR(50),
    next_run_at TIMESTAMP,
    description TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(255),

    -- çº¦æŸ
    CHECK (max_concurrent IS NULL OR max_concurrent > 0)
);

-- ä»»åŠ¡æ‰§è¡Œå†å²è¡¨
CREATE TABLE job_executions (
    id BIGSERIAL PRIMARY KEY,
    job_id INTEGER NOT NULL REFERENCES jobs(id) ON DELETE CASCADE,
    job_name VARCHAR(255) NOT NULL,
    execution_id UUID NOT NULL DEFAULT gen_random_uuid(),
    worker_id VARCHAR(255),
    started_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    duration_ms INTEGER,
    status VARCHAR(50) NOT NULL,
    retry_count INTEGER NOT NULL DEFAULT 0,
    error_message TEXT,
    error_details JSONB,
    result JSONB
);

-- ç´¢å¼•
CREATE INDEX idx_jobs_enabled ON jobs(enabled) WHERE enabled = true;
CREATE INDEX idx_jobs_next_run ON jobs(next_run_at) WHERE enabled = true;
CREATE INDEX idx_job_executions_job_id ON job_executions(job_id);
CREATE INDEX idx_job_executions_status ON job_executions(status);
```

**åˆ›å»ºæ–‡ä»¶ï¼š`migrations/{timestamp}_create_jobs_tables/down.sql`**

```sql
DROP TABLE IF EXISTS job_executions CASCADE;
DROP TABLE IF EXISTS jobs CASCADE;
```

**æ‰§è¡Œè¿ç§»ï¼š**
```bash
diesel migration run
```

#### 3. æ›´æ–° Schema

**æ–‡ä»¶ï¼š`src/schema.rs`**

è¿è¡Œ `diesel print-schema` åï¼Œå°†ç”Ÿæˆçš„ `jobs` å’Œ `job_executions` è¡¨å®šä¹‰æ·»åŠ åˆ° schema.rsã€‚

#### 4. æ‰©å±•é…ç½®ç³»ç»Ÿ

**æ–‡ä»¶ï¼š`src/config/settings.rs`**

åœ¨æ–‡ä»¶æœ«å°¾ï¼ˆç¬¬ 535 è¡Œåï¼‰æ·»åŠ ï¼š

```rust
// ============================================================================
// Jobs Configuration
// ============================================================================

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct JobsConfig {
    #[serde(default)]
    pub enabled: bool,

    #[serde(default = "default_worker_concurrency")]
    pub worker_concurrency: usize,

    #[serde(default = "default_poll_interval")]
    pub poll_interval: u64,

    #[serde(default = "default_job_timeout")]
    pub job_timeout: u64,

    #[serde(default = "default_max_retries")]
    pub max_retries: u32,

    #[serde(default = "default_retry_delay")]
    pub retry_delay: u64,

    #[serde(default = "default_history_retention_days")]
    pub history_retention_days: u32,
}

fn default_worker_concurrency() -> usize { 4 }
fn default_poll_interval() -> u64 { 5 }
fn default_job_timeout() -> u64 { 300 }
fn default_max_retries() -> u32 { 3 }
fn default_retry_delay() -> u64 { 60 }
fn default_history_retention_days() -> u32 { 30 }

impl Default for JobsConfig {
    fn default() -> Self {
        Self {
            enabled: false,
            worker_concurrency: default_worker_concurrency(),
            poll_interval: default_poll_interval(),
            job_timeout: default_job_timeout(),
            max_retries: default_max_retries(),
            retry_delay: default_retry_delay(),
            history_retention_days: default_history_retention_days(),
        }
    }
}

impl JobsConfig {
    pub fn validate(&self) -> Result<(), ConfigError> {
        if self.enabled && self.worker_concurrency == 0 {
            return Err(ConfigError::ValidationError {
                field: "jobs.worker_concurrency".to_string(),
                message: "Worker concurrency must be at least 1".to_string(),
            });
        }
        Ok(())
    }
}
```

**ä¿®æ”¹ Settings ç»“æ„ï¼ˆç¬¬ 502-522 è¡Œï¼‰ï¼š**

```rust
pub struct Settings {
    #[serde(default)]
    pub application: ApplicationConfig,
    #[serde(default)]
    pub server: ServerConfig,
    #[serde(default)]
    pub database: DatabaseConfig,
    #[serde(default)]
    pub jwt: JwtConfig,
    #[serde(default)]
    pub logger: LoggerSettings,

    // æ–°å¢
    #[serde(default)]
    pub jobs: JobsConfig,
}

impl Default for Settings {
    fn default() -> Self {
        Self {
            application: ApplicationConfig::default(),
            server: ServerConfig::default(),
            database: DatabaseConfig::default(),
            jwt: JwtConfig::default(),
            logger: LoggerSettings::default(),
            jobs: JobsConfig::default(), // æ–°å¢
        }
    }
}
```

**ä¿®æ”¹ Settings::validate() æ–¹æ³•ï¼š**

åœ¨é…ç½®éªŒè¯é“¾ä¸­æ·»åŠ ï¼š

```rust
impl Settings {
    pub fn validate(&self) -> Result<(), ConfigError> {
        self.server.validate()?;
        self.database.validate()?;
        self.logger.validate()?;
        self.jobs.validate()?; // æ–°å¢
        Ok(())
    }
}
```

#### 5. æ›´æ–°é…ç½®æ–‡ä»¶

**æ–‡ä»¶ï¼š`config/default.toml`**

åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼š

```toml
# -----------------------------------------------------------------------------
# Jobs Scheduler Configuration
# -----------------------------------------------------------------------------
[jobs]
enabled = false
worker_concurrency = 4
poll_interval = 5
job_timeout = 300
max_retries = 3
retry_delay = 60
history_retention_days = 30
```

**æ–‡ä»¶ï¼š`config/development.toml`**

```toml
[jobs]
enabled = true
worker_concurrency = 2
poll_interval = 10
history_retention_days = 7
```

---

### ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒæ¨¡å—ï¼ˆä¼˜å…ˆçº§ï¼šP0ï¼‰

#### 6. åˆ›å»º Jobs æ¨¡å—ç»“æ„

```
src/jobs/
â”œâ”€â”€ mod.rs                 # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ error.rs               # é”™è¯¯å®šä¹‰
â”œâ”€â”€ types.rs               # JobTask trait å’Œç±»å‹
â”œâ”€â”€ models.rs              # Diesel æ•°æ®æ¨¡å‹
â”œâ”€â”€ repositories.rs        # æ•°æ®è®¿é—®å±‚
â”œâ”€â”€ scheduler.rs           # è°ƒåº¦å™¨æ ¸å¿ƒ
â”œâ”€â”€ tasks/                 # å…·ä½“ä»»åŠ¡å®ç°
â”‚   â”œâ”€â”€ mod.rs
â”‚   â””â”€â”€ data_cleanup.rs    # ç¤ºä¾‹ä»»åŠ¡
â””â”€â”€ api/                   # ä»»åŠ¡ç®¡ç† API
    â”œâ”€â”€ mod.rs
    â”œâ”€â”€ handlers.rs
    â””â”€â”€ dto.rs
```

#### 7. å®ç°æ ¸å¿ƒç±»å‹

**æ–‡ä»¶ï¼š`src/jobs/error.rs`**

```rust
use thiserror::Error;

#[derive(Debug, Error)]
pub enum JobError {
    #[error("ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {0}")]
    ExecutionFailed(String),

    #[error("ä»»åŠ¡è¶…æ—¶")]
    Timeout,

    #[error("ä»»åŠ¡é…ç½®æ— æ•ˆ: {0}")]
    InvalidConfig(String),

    #[error("Cron è¡¨è¾¾å¼æ— æ•ˆ: {0}")]
    InvalidCronExpression(String),

    #[error("ä»»åŠ¡æœªæ‰¾åˆ°: {0}")]
    JobNotFound(String),

    #[error("æ•°æ®åº“é”™è¯¯: {0}")]
    DatabaseError(#[from] diesel::result::Error),

    #[error("åºåˆ—åŒ–é”™è¯¯: {0}")]
    SerializationError(#[from] serde_json::Error),

    #[error("å†…éƒ¨é”™è¯¯: {0}")]
    InternalError(String),
}
```

**æ–‡ä»¶ï¼š`src/jobs/types.rs`**

```rust
use async_trait::async_trait;
use serde::{Deserialize, Serialize};

#[derive(Clone)]
pub struct JobContext {
    pub execution_id: uuid::Uuid,
    pub job_name: String,
    pub retry_count: u32,
    pub db_pool: crate::db::AsyncDbPool,
}

pub type JobResult<T = ()> = Result<T, crate::jobs::error::JobError>;

#[async_trait]
pub trait JobTask: Send + Sync + std::fmt::Debug {
    fn task_type() -> &'static str where Self: Sized;
    async fn execute(&self, ctx: JobContext) -> JobResult<()>;
    fn description(&self) -> Option<String> { None }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum JobStatus {
    Pending, Running, Success, Failed, Timeout,
}
```

**æ–‡ä»¶ï¼š`src/jobs/models.rs`**

å®šä¹‰ `Job` å’Œ `JobExecution` çš„ Diesel æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
- `Job` - Queryable ç»“æ„ï¼ˆåŒ…å« allow_concurrentã€max_concurrent å­—æ®µï¼‰
- `NewJob` - Insertable ç»“æ„
- `UpdateJob` - AsChangeset ç»“æ„
- `JobExecution` - æ‰§è¡Œå†å²æ¨¡å‹

å…³é”®å­—æ®µï¼š
```rust
pub struct Job {
    // ... å…¶ä»–å­—æ®µ
    pub allow_concurrent: bool,        // æ˜¯å¦å…è®¸å¹¶è¡Œ
    pub max_concurrent: Option<i32>,   // æœ€å¤§å¹¶å‘æ•°ï¼ˆNone è¡¨ç¤ºæ— é™åˆ¶ï¼‰
    // ...
}
```

**æ–‡ä»¶ï¼š`src/jobs/repositories.rs`**

å®ç° `JobRepository`ï¼Œæä¾›ï¼š
- `create_job()` - åˆ›å»ºä»»åŠ¡
- `get_enabled_jobs()` - æŸ¥è¯¢å¯ç”¨çš„ä»»åŠ¡
- `get_job_by_id()` - æŒ‰ ID æŸ¥è¯¢
- `update_job()` - æ›´æ–°ä»»åŠ¡
- `delete_job()` - åˆ é™¤ä»»åŠ¡

**æ–‡ä»¶ï¼š`src/jobs/mod.rs`**

```rust
pub mod scheduler;
pub mod models;
pub mod repositories;
pub mod types;
pub mod tasks;
pub mod api;
pub mod error;

pub use scheduler::JobScheduler;
pub use types::{JobTask, JobContext, JobResult};
pub use error::JobError;
```

---

### ç¬¬ä¸‰é˜¶æ®µï¼šApalis é›†æˆï¼ˆä¼˜å…ˆçº§ï¼šP0ï¼‰

#### 8. Apalis å†…ç½®åŠŸèƒ½ä½¿ç”¨æŒ‡å—

**é‡è¦**: apalis å·²ç»å†…ç½®äº†å¤§éƒ¨åˆ†ä»»åŠ¡é˜Ÿåˆ—åŠŸèƒ½,æˆ‘ä»¬åªéœ€è¦æ­£ç¡®é…ç½®å’Œä½¿ç”¨,æ— éœ€é‡å¤å®ç°ã€‚

##### 8.1 é‡è¯•ç­–ç•¥(ä½¿ç”¨ apalis å†…ç½®)

```rust
use apalis::layers::retry::{RetryPolicy, ExponentialBackoffMaker, HasherRng};
use std::time::Duration;

// é…ç½®æŒ‡æ•°é€€é¿é‡è¯•
let backoff = ExponentialBackoffMaker::new(
    Duration::from_secs(config.retry_delay),  // èµ·å§‹å»¶è¿Ÿ
    Duration::from_secs(config.retry_delay * 10),  // æœ€å¤§å»¶è¿Ÿ
    2.0,  // å€æ•°
    HasherRng::default(),
)?.make_backoff();

WorkerBuilder::new("task-worker")
    .backend(backend)
    .retry(
        RetryPolicy::retries(config.max_retries)
            .with_backoff(backoff)
            .retry_if(|e: &BoxDynError| {
                // è‡ªå®šä¹‰é‡è¯•æ¡ä»¶
                !e.to_string().contains("permanent")
            })
    )
    .build(task_handler)
```

##### 8.2 è¶…æ—¶å¤„ç†(ä½¿ç”¨ TaskBuilder)

```rust
use apalis_core::task::builder::TaskBuilder;

// åˆ›å»ºå¸¦è¶…æ—¶çš„ä»»åŠ¡
let task = TaskBuilder::new(job_data)
    .timeout(Duration::from_secs(job.timeout_seconds as u64))
    .attempts(job.max_retries as usize)
    .build();

storage.push_task(task).await?;
```

##### 8.3 ä¼˜é›…å…³é—­(ä½¿ç”¨ Monitor)

```rust
use apalis::prelude::*;

// åˆ›å»º Monitor å¹¶é…ç½®ä¼˜é›…å…³é—­
Monitor::new()
    .register(|_| worker)
    .shutdown_timeout(Duration::from_secs(30))  // ç­‰å¾…ä»»åŠ¡å®Œæˆçš„è¶…æ—¶æ—¶é—´
    .run_with_signal(tokio::signal::ctrl_c())   // ç›‘å¬ Ctrl+C ä¿¡å·
    .await?;

// ä»»åŠ¡å†…éƒ¨å¯ä»¥æ£€æŸ¥å…³é—­çŠ¶æ€
async fn task_handler(job: Job, worker: WorkerContext) -> Result<(), BoxDynError> {
    loop {
        if worker.is_shutting_down() {
            tracing::info!("æ£€æµ‹åˆ°å…³é—­ä¿¡å·,ä¿å­˜çŠ¶æ€å¹¶é€€å‡º");
            // ä¿å­˜ä»»åŠ¡çŠ¶æ€
            break;
        }
        // å¤„ç†ä»»åŠ¡
    }
    Ok(())
}
```

##### 8.4 Prometheus ç›‘æ§(ä½¿ç”¨ PrometheusLayer)

```rust
use apalis::layers::prometheus::PrometheusLayer;
use metrics_exporter_prometheus::PrometheusBuilder;

// è®¾ç½® Prometheus recorder
let recorder = PrometheusBuilder::new()
    .install_recorder()
    .expect("Failed to install Prometheus recorder");

// æ·»åŠ ç›‘æ§å±‚
WorkerBuilder::new("monitored-worker")
    .backend(backend)
    .layer(PrometheusLayer::default())  // è‡ªåŠ¨æ”¶é›†æŒ‡æ ‡
    .build(task_handler)

// æŒ‡æ ‡è‡ªåŠ¨åŒ…æ‹¬:
// - apalis_jobs_total{job_type, status}
// - apalis_job_duration_seconds{job_type}
// - apalis_jobs_active{job_type}
```

##### 8.5 å¹¶å‘æ§åˆ¶(ä½¿ç”¨ WorkerBuilder)

```rust
// Worker çº§åˆ«çš„å¹¶å‘æ§åˆ¶
WorkerBuilder::new("concurrent-worker")
    .backend(backend)
    .concurrency(config.worker_concurrency)  // æœ€å¤šåŒæ—¶å¤„ç† N ä¸ªä»»åŠ¡
    .build(task_handler)
```

##### 8.6 ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ç›‘å¬

```rust
WorkerBuilder::new("event-worker")
    .backend(backend)
    .on_event(|ctx, event| {
        match event {
            Event::Start => tracing::info!("Worker {} å¯åŠ¨", ctx.name()),
            Event::Engage => tracing::debug!("å¼€å§‹å¤„ç†ä»»åŠ¡"),
            Event::Idle => tracing::debug!("ç­‰å¾…ä»»åŠ¡"),
            Event::Error(err) => tracing::error!("ä»»åŠ¡é”™è¯¯: {:?}", err),
            Event::Stop => tracing::info!("Worker {} åœæ­¢", ctx.name()),
        }
    })
    .build(task_handler)
```

---

#### 9. å®ç°è°ƒåº¦å™¨æ ¸å¿ƒ

**æ–‡ä»¶ï¼š`src/jobs/scheduler.rs`**

**è®¾è®¡æ€è·¯**: ä½¿ç”¨ apalis Monitor ç®¡ç† workers,åªéœ€å®ç° Cron è°ƒåº¦å’Œä»»åŠ¡çº§å¹¶å‘æ§åˆ¶ã€‚

```rust
use crate::config::JobsConfig;
use crate::db::AsyncDbPool;
use crate::jobs::error::JobError;
use crate::jobs::repositories::JobRepository;
use apalis::prelude::*;
use apalis::layers::retry::{RetryPolicy, ExponentialBackoffMaker, HasherRng};
use apalis::layers::prometheus::PrometheusLayer;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use std::time::Duration;

pub struct JobScheduler {
    config: JobsConfig,
    db_pool: AsyncDbPool,
    repository: JobRepository,
    monitor: Option<Monitor<TokioExecutor>>,

    // ä»»åŠ¡çº§å¹¶å‘æ§åˆ¶(ä»éœ€è‡ªå·±å®ç°)
    running_counts: Arc<RwLock<HashMap<String, usize>>>,
}

impl JobScheduler {
    pub async fn new(db_pool: AsyncDbPool, config: JobsConfig) -> Result<Self, JobError> {
        config.validate()
            .map_err(|e| JobError::InvalidConfig(e.to_string()))?;

        let repository = JobRepository::new(db_pool.clone());

        Ok(Self {
            config,
            db_pool,
            repository,
            monitor: None,
            running_counts: Arc::new(RwLock::new(HashMap::new())),
        })
    }

    pub async fn start(&mut self) -> Result<(), JobError> {
        if !self.config.enabled {
            tracing::info!("ä»»åŠ¡è°ƒåº¦å™¨å·²ç¦ç”¨");
            return Ok(());
        }

        tracing::info!(
            worker_concurrency = self.config.worker_concurrency,
            "å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨"
        );

        // 1. åˆ›å»º PostgreSQL å­˜å‚¨åç«¯
        let storage = apalis_sql::postgres::PostgresStorage::new(self.db_pool.clone());

        // 2. é…ç½®é‡è¯•ç­–ç•¥
        let backoff = ExponentialBackoffMaker::new(
            Duration::from_secs(self.config.retry_delay),
            Duration::from_secs(self.config.retry_delay * 10),
            2.0,
            HasherRng::default(),
        )?.make_backoff();

        // 3. åˆ›å»º Worker
        let worker = WorkerBuilder::new("fusion-job-worker")
            .backend(storage)
            .concurrency(self.config.worker_concurrency)
            .retry(
                RetryPolicy::retries(self.config.max_retries)
                    .with_backoff(backoff)
            )
            .layer(PrometheusLayer::default())  // ç›‘æ§
            .on_event(|ctx, event| {
                match event {
                    Event::Start => tracing::info!("Worker {} å¯åŠ¨", ctx.name()),
                    Event::Error(err) => tracing::error!("ä»»åŠ¡é”™è¯¯: {:?}", err),
                    Event::Stop => tracing::info!("Worker {} åœæ­¢", ctx.name()),
                    _ => {}
                }
            })
            .build(self.task_handler());

        // 4. åˆ›å»º Monitor å¹¶å¯åŠ¨
        let monitor = Monitor::new()
            .register(move |_| worker)
            .shutdown_timeout(Duration::from_secs(30));

        // å¯åŠ¨åå°ä»»åŠ¡
        let monitor_handle = tokio::spawn(async move {
            monitor.run().await
        });

        self.monitor = Some(monitor_handle);

        // 5. å¯åŠ¨ Cron è°ƒåº¦å™¨(å®šæœŸæ‰«æ jobs è¡¨å¹¶æ¨é€ä»»åŠ¡)
        self.start_cron_scheduler().await?;

        Ok(())
    }

    // Cron è°ƒåº¦å™¨(éœ€è¦è‡ªå·±å®ç°)
    async fn start_cron_scheduler(&self) -> Result<(), JobError> {
        let repository = self.repository.clone();
        let poll_interval = self.config.poll_interval;

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(poll_interval));
            loop {
                interval.tick().await;

                // æŸ¥è¯¢éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡
                match repository.get_jobs_to_run().await {
                    Ok(jobs) => {
                        for job in jobs {
                            // æ£€æŸ¥ä»»åŠ¡çº§å¹¶å‘æ§åˆ¶
                            if !self.can_execute_job(&job.job_name, &job).await {
                                continue;
                            }

                            // æ¨é€ä»»åŠ¡åˆ° apalis
                            // TODO: å®ç°ä»»åŠ¡æ¨é€é€»è¾‘
                        }
                    }
                    Err(e) => {
                        tracing::error!("æŸ¥è¯¢å¾…æ‰§è¡Œä»»åŠ¡å¤±è´¥: {:?}", e);
                    }
                }
            }
        });

        Ok(())
    }

    // ä»»åŠ¡å¤„ç†å™¨
    fn task_handler(&self) -> impl Fn(JobData) -> BoxFuture<'static, Result<(), BoxDynError>> {
        let running_counts = self.running_counts.clone();

        move |job_data: JobData| {
            let counts = running_counts.clone();
            Box::pin(async move {
                // å¢åŠ è®¡æ•°
                {
                    let mut c = counts.write().await;
                    *c.entry(job_data.job_name.clone()).or_insert(0) += 1;
                }

                // æ‰§è¡Œä»»åŠ¡
                let result = execute_job(job_data).await;

                // å‡å°‘è®¡æ•°
                {
                    let mut c = counts.write().await;
                    if let Some(count) = c.get_mut(&job_data.job_name) {
                        *count = count.saturating_sub(1);
                        if *count == 0 {
                            c.remove(&job_data.job_name);
                        }
                    }
                }

                result
            })
        }
    }

    // æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¯ä»¥æ‰§è¡Œ(å¹¶å‘æ§åˆ¶)
    async fn can_execute_job(&self, job_name: &str, job: &Job) -> bool {
        if !job.allow_concurrent {
            let counts = self.running_counts.read().await;
            if let Some(count) = counts.get(job_name) {
                if *count > 0 {
                    tracing::debug!(
                        job_name = %job_name,
                        "ä»»åŠ¡ä¸å…è®¸å¹¶è¡Œï¼Œè·³è¿‡æ‰§è¡Œ"
                    );
                    return false;
                }
            }
        } else if let Some(max_concurrent) = job.max_concurrent {
            let counts = self.running_counts.read().await;
            if let Some(count) = counts.get(job_name) {
                if *count >= max_concurrent as usize {
                    tracing::debug!(
                        job_name = %job_name,
                        current_count = *count,
                        max_concurrent,
                        "ä»»åŠ¡å¹¶å‘æ•°å·²è¾¾ä¸Šé™ï¼Œè·³è¿‡æ‰§è¡Œ"
                    );
                    return false;
                }
            }
        }
        true
    }

    pub async fn stop(&mut self) -> Result<(), JobError> {
        if let Some(handle) = self.monitor.take() {
            tracing::info!("åœæ­¢ä»»åŠ¡è°ƒåº¦å™¨");
            // Monitor ä¼šè‡ªåŠ¨ä¼˜é›…å…³é—­
            handle.abort();
        }
        Ok(())
    }

    pub fn repository(&self) -> &JobRepository {
        &self.repository
    }
}
```

**å…³é”®æ”¹è¿›**:
1. âœ… ä½¿ç”¨ apalis Monitor ç®¡ç† workers
2. âœ… ä½¿ç”¨ apalis å†…ç½®çš„é‡è¯•ã€è¶…æ—¶ã€ç›‘æ§åŠŸèƒ½
3. âœ… åªéœ€å®ç° Cron è°ƒåº¦é€»è¾‘å’Œä»»åŠ¡çº§å¹¶å‘æ§åˆ¶
4. âœ… ä»£ç é‡å‡å°‘çº¦ 60%

#### 9. é›†æˆåˆ° Server

**æ–‡ä»¶ï¼š`src/server.rs`**

åœ¨ `Server::run()` æ–¹æ³•ä¸­ï¼ˆç¬¬ 92-97 è¡Œåï¼‰æ·»åŠ ï¼š

```rust
// åˆ›å»ºåº”ç”¨çŠ¶æ€
let state = AppState::new(pool.clone(), self.settings.jwt.clone());
tracing::info!("Application state created");

// åˆå§‹åŒ–å¹¶å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
let mut scheduler = None;
if self.settings.jobs.enabled {
    tracing::info!("åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨");

    self.settings.jobs.validate().map_err(|e| {
        tracing::error!(error = %e, "Jobs é…ç½®éªŒè¯å¤±è´¥");
        anyhow::anyhow!("Jobs configuration validation failed: {}", e)
    })?;

    let mut job_scheduler = crate::jobs::scheduler::JobScheduler::new(
        pool.clone(),
        self.settings.jobs.clone(),
    ).await?;

    job_scheduler.start().await?;
    scheduler = Some(job_scheduler);
}

// åˆ›å»ºè·¯ç”±
let router = create_router(state);
```

åœ¨ `shutdown_signal()` è°ƒç”¨åæ·»åŠ æ¸…ç†é€»è¾‘ï¼š

```rust
axum::serve(listener, router)
    .with_graceful_shutdown(shutdown_signal())
    .await?;

// åœæ­¢è°ƒåº¦å™¨
if let Some(mut sched) = scheduler {
    sched.stop().await?;
}

tracing::info!("Server shutdown complete");
```

---

### ç¬¬å››é˜¶æ®µï¼šç¤ºä¾‹ä»»åŠ¡ï¼ˆä¼˜å…ˆçº§ï¼šP1ï¼‰

#### 10. å®ç°æ•°æ®æ¸…ç†ä»»åŠ¡

**æ–‡ä»¶ï¼š`src/jobs/tasks/data_cleanup.rs`**

```rust
use crate::jobs::error::JobError;
use crate::jobs::types::{JobContext, JobResult, JobTask};
use crate::schema::job_executions;
use async_trait::async_trait;
use chrono::{Duration, Utc};
use diesel::prelude::*;
use diesel_async::RunQueryDsl;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataCleanupTask {
    pub retention_days: i64,
}

#[async_trait]
impl JobTask for DataCleanupTask {
    fn task_type() -> &'static str {
        "data_cleanup"
    }

    async fn execute(&self, ctx: JobContext) -> JobResult<()> {
        tracing::info!(
            execution_id = %ctx.execution_id,
            job_name = %ctx.job_name,
            retention_days = self.retention_days,
            "å¼€å§‹æ‰§è¡Œæ•°æ®æ¸…ç†ä»»åŠ¡"
        );

        let cutoff_date = Utc::now().naive_utc() - Duration::days(self.retention_days);

        let mut conn = ctx.pool.get().await.map_err(|e| {
            JobError::DatabaseError(diesel::result::Error::DatabaseError(
                diesel::result::DatabaseErrorKind::UnableToSendCommand,
                Box::new(e.to_string()),
            ))
        })?;

        let deleted_count = diesel::delete(
            job_executions::table.filter(
                job_executions::started_at
                    .lt(cutoff_date)
                    .and(job_executions::status.ne("running"))
            )
        )
        .execute(&mut conn)
        .await
        .map_err(JobError::DatabaseError)?;

        tracing::info!(
            execution_id = %ctx.execution_id,
            deleted_count,
            "æ•°æ®æ¸…ç†ä»»åŠ¡å®Œæˆ"
        );

        Ok(())
    }

    fn description(&self) -> Option<String> {
        Some(format!("æ¸…ç† {} å¤©å‰çš„ä»»åŠ¡æ‰§è¡Œå†å²", self.retention_days))
    }
}

impl Default for DataCleanupTask {
    fn default() -> Self {
        Self { retention_days: 30 }
    }
}
```

**æ–‡ä»¶ï¼š`src/jobs/tasks/mod.rs`**

```rust
pub mod data_cleanup;
pub use data_cleanup::DataCleanupTask;
```

---

### ç¬¬äº”é˜¶æ®µï¼šåŠ¨æ€ç®¡ç† APIï¼ˆä¼˜å…ˆçº§ï¼šP1ï¼‰

#### 11. å®ç° API DTO

**æ–‡ä»¶ï¼š`src/jobs/api/dto.rs`**

å®šä¹‰ï¼š
- `CreateJobRequest` - åˆ›å»ºä»»åŠ¡è¯·æ±‚
  ```rust
  pub struct CreateJobRequest {
      pub job_name: String,
      pub job_type: String,
      pub cron_expression: Option<String>,
      pub enabled: bool,

      // å¹¶å‘æ§åˆ¶ï¼ˆæ–°å¢ï¼‰
      pub allow_concurrent: bool,
      pub max_concurrent: Option<i32>,

      pub max_retries: i32,
      pub payload: Option<JsonValue>,
      pub description: Option<String>,
  }
  ```
- `UpdateJobRequest` - æ›´æ–°ä»»åŠ¡è¯·æ±‚
- `JobResponse` - ä»»åŠ¡è¯¦æƒ…å“åº”ï¼ˆåŒ…å«å¹¶å‘æ§åˆ¶å­—æ®µï¼‰
- `JobExecutionResponse` - æ‰§è¡Œå†å²å“åº”

#### 12. å®ç° API Handlers

**æ–‡ä»¶ï¼š`src/jobs/api/handlers.rs`**

å®ç°ç«¯ç‚¹ï¼š
- `POST /api/jobs` - åˆ›å»ºä»»åŠ¡
- `GET /api/jobs` - æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨
- `GET /api/jobs/{id}` - æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…
- `PUT /api/jobs/{id}` - æ›´æ–°ä»»åŠ¡
- `DELETE /api/jobs/{id}` - åˆ é™¤ä»»åŠ¡
- `POST /api/jobs/{id}/pause` - æš‚åœä»»åŠ¡
- `POST /api/jobs/{id}/resume` - æ¢å¤ä»»åŠ¡
- `GET /api/jobs/{id}/executions` - æŸ¥è¯¢æ‰§è¡Œå†å²

**æ–‡ä»¶ï¼š`src/jobs/api/mod.rs`**

```rust
pub mod handlers;
pub mod dto;
```

#### 13. é›†æˆåˆ°è·¯ç”±

**æ–‡ä»¶ï¼š`src/api/routes.rs`**

åœ¨å—ä¿æŠ¤è·¯ç”±ä¸­ï¼ˆç¬¬ 51 è¡Œåï¼‰æ·»åŠ ï¼š

```rust
let protected_routes = OpenApiRouter::new()
    .nest("/me", handlers::me::me_routes())
    .nest("/users", handlers::users::user_routes())
    .nest("/jobs", crate::jobs::api::handlers::job_routes()) // æ–°å¢
    .layer(middleware::from_fn_with_state(state.clone(), auth_middleware));
```

---

## å…³é”®æ–‡ä»¶æ¸…å•

### éœ€è¦ä¿®æ”¹çš„ç°æœ‰æ–‡ä»¶

1. `Cargo.toml` - æ·»åŠ  apalis ç›¸å…³ä¾èµ–
2. `src/config/settings.rs` - æ‰©å±• JobsConfigï¼ˆç¬¬ 535 è¡Œåï¼‰
3. `src/server.rs` - é›†æˆè°ƒåº¦å™¨å¯åŠ¨å’Œåœæ­¢ï¼ˆç¬¬ 92-120 è¡Œï¼‰
4. `src/api/routes.rs` - æ·»åŠ  jobs API è·¯ç”±ï¼ˆç¬¬ 51 è¡Œåï¼‰
5. `config/default.toml` - æ·»åŠ  jobs é…ç½®æ®µï¼ˆæ–‡ä»¶æœ«å°¾ï¼‰
6. `config/development.toml` - å¼€å‘ç¯å¢ƒé…ç½®è¦†ç›–ï¼ˆæ–‡ä»¶æœ«å°¾ï¼‰

### éœ€è¦åˆ›å»ºçš„æ–°æ–‡ä»¶

7. `migrations/{timestamp}_create_jobs_tables/up.sql` - æ•°æ®åº“ schema
8. `migrations/{timestamp}_create_jobs_tables/down.sql` - å›æ»šè„šæœ¬
9. `src/jobs/mod.rs` - æ¨¡å—å¯¼å‡º
10. `src/jobs/error.rs` - é”™è¯¯å®šä¹‰
11. `src/jobs/types.rs` - JobTask trait
12. `src/jobs/models.rs` - Diesel æ¨¡å‹
13. `src/jobs/repositories.rs` - æ•°æ®è®¿é—®å±‚
14. `src/jobs/scheduler.rs` - è°ƒåº¦å™¨æ ¸å¿ƒ
15. `src/jobs/tasks/mod.rs` - ä»»åŠ¡æ¨¡å—
16. `src/jobs/tasks/data_cleanup.rs` - ç¤ºä¾‹ä»»åŠ¡
17. `src/jobs/api/mod.rs` - API æ¨¡å—
18. `src/jobs/api/dto.rs` - API DTO
19. `src/jobs/api/handlers.rs` - API handlers

### éœ€è¦æ›´æ–°çš„æ–‡ä»¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰

20. `src/schema.rs` - è¿è¡Œ `diesel print-schema` åæ›´æ–°

---

## è®¾è®¡åŸåˆ™ä½“ç°

### SOLID åŸåˆ™

- **å•ä¸€èŒè´£ï¼ˆSRPï¼‰**ï¼š
  - `JobRepository` ä»…è´Ÿè´£æ•°æ®è®¿é—®
  - `JobScheduler` ä»…è´Ÿè´£è°ƒåº¦é€»è¾‘
  - æ¯ä¸ªä»»åŠ¡å®ç°ç‹¬ç«‹çš„ `JobTask` trait

- **å¼€é—­åŸåˆ™ï¼ˆOCPï¼‰**ï¼š
  - é€šè¿‡ `JobTask` trait æ‰©å±•æ–°ä»»åŠ¡ï¼Œæ— éœ€ä¿®æ”¹è°ƒåº¦å™¨
  - é…ç½®ç³»ç»Ÿé€šè¿‡ `serde` è‡ªåŠ¨ååºåˆ—åŒ–ï¼Œæ˜“äºæ‰©å±•

- **é‡Œæ°æ›¿æ¢åŸåˆ™ï¼ˆLSPï¼‰**ï¼š
  - æ‰€æœ‰å®ç° `JobTask` çš„ä»»åŠ¡å¯äº’æ¢ä½¿ç”¨

- **æ¥å£éš”ç¦»åŸåˆ™ï¼ˆISPï¼‰**ï¼š
  - `JobTask` trait ä»…å®šä¹‰å¿…éœ€æ–¹æ³•
  - Repository æ¥å£èŒè´£æ˜ç¡®

- **ä¾èµ–åè½¬åŸåˆ™ï¼ˆDIPï¼‰**ï¼š
  - è°ƒåº¦å™¨ä¾èµ– `JobTask` trait æŠ½è±¡ï¼Œè€Œéå…·ä½“å®ç°
  - é€šè¿‡ `AsyncDbPool` æŠ½è±¡æ•°æ®åº“è®¿é—®

### KISS & DRY

- **KISS**ï¼šä½¿ç”¨æˆç†Ÿçš„ apalis åº“ï¼Œé¿å…é‡å¤é€ è½®å­
- **DRY**ï¼šå¤ç”¨ç°æœ‰çš„æ•°æ®åº“è¿æ¥æ± ã€é…ç½®ç³»ç»Ÿã€æ—¥å¿—æ¡†æ¶

---

## éªŒè¯å’Œæµ‹è¯•

### åŠŸèƒ½éªŒè¯æ¸…å•

- [ ] é…ç½®åŠ è½½å’ŒéªŒè¯æ­£å¸¸
- [ ] æ•°æ®åº“ migrations æˆåŠŸ
- [ ] è°ƒåº¦å™¨å¯åŠ¨å’Œåœæ­¢æ­£å¸¸
- [ ] ç¤ºä¾‹ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ
- [ ] ä»»åŠ¡å¤±è´¥è‡ªåŠ¨é‡è¯•
- [ ] æ‰§è¡Œå†å²æ­£ç¡®è®°å½•
- [ ] API ç«¯ç‚¹æ­£å¸¸å·¥ä½œ
- [ ] åŠ¨æ€åˆ›å»º/åˆ é™¤/æš‚åœä»»åŠ¡
- [ ] ä¼˜é›…å…³é—­ä¸ä¸¢å¤±ä»»åŠ¡
- [ ] **ä»»åŠ¡å¹¶å‘æ§åˆ¶æ­£å¸¸å·¥ä½œ**ï¼ˆæ–°å¢ï¼‰
  - [ ] ä¸å…è®¸å¹¶è¡Œçš„ä»»åŠ¡åªè¿è¡Œä¸€ä¸ªå®ä¾‹
  - [ ] æœ‰æœ€å¤§å¹¶å‘é™åˆ¶çš„ä»»åŠ¡ä¸è¶…è¿‡é…ç½®å€¼
  - [ ] æ— é™åˆ¶çš„ä»»åŠ¡å¯ä»¥åŒæ—¶è¿è¡Œå¤šä¸ªå®ä¾‹

### æµ‹è¯•ç­–ç•¥

1. **å•å…ƒæµ‹è¯•**ï¼šRepositoryã€Task å®ç°
2. **é›†æˆæµ‹è¯•**ï¼šè°ƒåº¦å™¨ + æ•°æ®åº“
3. **ç«¯åˆ°ç«¯æµ‹è¯•**ï¼šå®Œæ•´å·¥ä½œæµ

---

## é£é™©å’Œæ³¨æ„äº‹é¡¹

### æ½œåœ¨é£é™©

1. **apalis ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šç¡®ä¿ apalis-sql 0.7 ä¸ diesel-async å…¼å®¹
2. **æ•°æ®åº“è¿æ¥æ± è€—å°½**ï¼šä»»åŠ¡æ‰§è¡Œæ—¶æ³¨æ„è¿æ¥æ± å¤§å°
3. **é•¿æ—¶é—´è¿è¡Œä»»åŠ¡**ï¼šéœ€è¦åˆç†è®¾ç½® timeout
4. **åˆ†å¸ƒå¼åœºæ™¯**ï¼šPostgreSQL SKIP LOCKED æœºåˆ¶éœ€æµ‹è¯•

### ç¼“è§£æªæ–½

- ä¸¥æ ¼ç‰ˆæœ¬é”å®šï¼Œé¿å…ç ´åæ€§å‡çº§
- ç›‘æ§æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡
- é…ç½®åˆç†çš„è¶…æ—¶å’Œé‡è¯•ç­–ç•¥
- å¤šå®ä¾‹éƒ¨ç½²å‰è¿›è¡Œå……åˆ†æµ‹è¯•

---

## å®æ–½æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|-----|------|---------|
| 1 | åŸºç¡€è®¾æ–½ï¼ˆä¾èµ–ã€schemaã€é…ç½®ï¼‰ | 2 å°æ—¶ |
| 2 | æ ¸å¿ƒæ¨¡å—ï¼ˆtypesã€modelsã€repositoryï¼‰ | 2 å°æ—¶ | ç®€åŒ–(-1h) |
| 3 | è°ƒåº¦å™¨å®ç°ï¼ˆscheduler.rs + é›†æˆï¼‰ | 4 å°æ—¶ | ä½¿ç”¨å†…ç½®åŠŸèƒ½(-2h) |
| 4 | ç¤ºä¾‹ä»»åŠ¡ï¼ˆdata_cleanupï¼‰ | 1 å°æ—¶ |
| 5 | åŠ¨æ€ç®¡ç† API | 3 å°æ—¶ |
| 6 | æµ‹è¯•å’Œæ–‡æ¡£ | 3 å°æ—¶ | å¢åŠ é›†æˆæµ‹è¯•(+1h) |
| **æ€»è®¡** | | **15 å°æ—¶** |

---

## å¹¶å‘æ§åˆ¶è¯¦ç»†è¯´æ˜

### ä¸‰ç§å¹¶å‘æ¨¡å¼

#### æ¨¡å¼ 1ï¼šå®Œå…¨ç¦æ­¢å¹¶è¡Œ
```sql
allow_concurrent = false
max_concurrent = NULL
```
- åŒä¸€ä»»åŠ¡åªèƒ½æœ‰ä¸€ä¸ªå®ä¾‹åœ¨è¿è¡Œ
- å¦‚æœå·²æœ‰å®ä¾‹è¿è¡Œï¼Œæ–°çš„è°ƒåº¦ä¼šè¢«è·³è¿‡
- é€‚ç”¨äºï¼šæ•°æ®åº“å¤‡ä»½ã€æ•°æ®è¿ç§»ç­‰ä¸èƒ½åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡

#### æ¨¡å¼ 2ï¼šé™åˆ¶æœ€å¤§å¹¶å‘æ•°
```sql
allow_concurrent = true
max_concurrent = 3  -- æœ€å¤šåŒæ—¶è¿è¡Œ 3 ä¸ªå®ä¾‹
```
- å…è®¸å¤šä¸ªå®ä¾‹å¹¶è¡Œï¼Œä½†ä¸è¶…è¿‡ max_concurrent
- è¶…è¿‡é™åˆ¶æ—¶ï¼Œæ–°çš„è°ƒåº¦ä¼šè¢«è·³è¿‡
- é€‚ç”¨äºï¼šAPI è°ƒç”¨ã€æ•°æ®å¤„ç†ç­‰æœ‰èµ„æºé™åˆ¶çš„ä»»åŠ¡

#### æ¨¡å¼ 3ï¼šæ— é™åˆ¶å¹¶è¡Œ
```sql
allow_concurrent = true
max_concurrent = NULL
```
- ä»»æ„æ•°é‡çš„å®ä¾‹å¯ä»¥åŒæ—¶è¿è¡Œ
- æ²¡æœ‰å¹¶å‘é™åˆ¶
- é€‚ç”¨äºï¼šæ—¥å¿—æ¸…ç†ã€ç¼“å­˜é¢„çƒ­ç­‰è½»é‡çº§ä»»åŠ¡

### å®ç°æœºåˆ¶

è°ƒåº¦å™¨ç»´æŠ¤ä¸€ä¸ªå†…å­˜ä¸­çš„å¹¶å‘è®¡æ•°å™¨ `running_counts: HashMap<job_name, count>`ï¼š

1. **æ‰§è¡Œå‰æ£€æŸ¥**ï¼š
   ```rust
   if !allow_concurrent && running_count > 0 {
       skip_execution();
   }
   if max_concurrent.is_some() && running_count >= max_concurrent {
       skip_execution();
   }
   ```

2. **æ‰§è¡Œä¸­è®¡æ•°**ï¼š
   - ä»»åŠ¡å¼€å§‹æ—¶ï¼š`increment_running_count(job_name)`
   - ä»»åŠ¡ç»“æŸæ—¶ï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰ï¼š`decrement_running_count(job_name)`

3. **åˆ†å¸ƒå¼åœºæ™¯**ï¼š
   - å•å®ä¾‹éƒ¨ç½²ï¼šå†…å­˜è®¡æ•°å™¨å³å¯
   - å¤šå®ä¾‹éƒ¨ç½²ï¼šéœ€ä½¿ç”¨ PostgreSQL advisory locks æˆ– Redis åˆ†å¸ƒå¼é”

### é…ç½®ç¤ºä¾‹

```toml
# ç¤ºä¾‹ 1ï¼šæ¯æ—¥æ•°æ®åº“å¤‡ä»½ï¼ˆä¸å…è®¸å¹¶è¡Œï¼‰
[[jobs.jobs]]
job_name = "daily_backup"
cron = "0 2 * * *"
allow_concurrent = false
max_concurrent = null

# ç¤ºä¾‹ 2ï¼šå®šæœŸ API åŒæ­¥ï¼ˆæœ€å¤š 3 ä¸ªå¹¶è¡Œï¼‰
[[jobs.jobs]]
job_name = "api_sync"
cron = "*/10 * * * *"
allow_concurrent = true
max_concurrent = 3

# ç¤ºä¾‹ 3ï¼šç¼“å­˜æ¸…ç†ï¼ˆæ— é™åˆ¶ï¼‰
[[jobs.jobs]]
job_name = "cache_cleanup"
cron = "0 * * * *"
allow_concurrent = true
max_concurrent = null
```

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… ç”¨æˆ·ç¡®è®¤è®¡åˆ’ï¼ˆåŒ…å«å¹¶å‘æ§åˆ¶éœ€æ±‚ï¼‰
2. æ‰§è¡Œç¬¬ä¸€é˜¶æ®µï¼ˆåŸºç¡€è®¾æ–½ï¼‰
3. é€æ­¥å®æ–½å„é˜¶æ®µ
4. æŒç»­æµ‹è¯•å’ŒéªŒè¯ï¼ˆåŒ…æ‹¬å¹¶å‘æ§åˆ¶æµ‹è¯•ï¼‰
5. å®Œæˆæ–‡æ¡£æ›´æ–°

---

## Apalis åŠŸèƒ½æ€»ç»“

### âœ… Apalis å·²è§£å†³çš„é—®é¢˜

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|-----|------|------|
| é‡è¯•ç­–ç•¥ | âœ… å®Œç¾æ”¯æŒ | å†…ç½®æŒ‡æ•°é€€é¿,å¯è‡ªå®šä¹‰é‡è¯•æ¡ä»¶ |
| è¶…æ—¶å¤„ç† | âœ… å®Œç¾æ”¯æŒ | TaskBuilder.timeout() |
| ä¼˜é›…å…³é—­ | âœ… å®Œç¾æ”¯æŒ | Monitor.shutdown_timeout() + WorkerContext.is_shutting_down() |
| Prometheus ç›‘æ§ | âœ… å®Œç¾æ”¯æŒ | PrometheusLayer è‡ªåŠ¨æ”¶é›†æŒ‡æ ‡ |
| Worker å¹¶å‘æ§åˆ¶ | âœ… å®Œç¾æ”¯æŒ | WorkerBuilder.concurrency() |
| ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ | âœ… å®Œç¾æ”¯æŒ | on_event() ç›‘å¬ Start/Engage/Idle/Error/Stop |
| åˆ†å¸ƒå¼æ”¯æŒ | âœ… å®Œç¾æ”¯æŒ | PostgreSQL/Redis åç«¯å¤©ç„¶æ”¯æŒå¤šå®ä¾‹ |

### âš ï¸ éœ€è¦è‡ªå·±å®ç°çš„åŠŸèƒ½

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|-----|------|------|
| Cron è¡¨è¾¾å¼è°ƒåº¦ | âš ï¸ éœ€å®ç° | apalis-cron æ–‡æ¡£ä¸è¶³,éœ€è‡ªå·±å®ç°å®šæœŸæ‰«æ jobs è¡¨ |
| ä»»åŠ¡çº§å¹¶å‘æ§åˆ¶ | âš ï¸ éœ€å®ç° | allow_concurrent/max_concurrent éœ€ä½¿ç”¨ PostgreSQL advisory locks |
| ä»»åŠ¡ä¼˜å…ˆçº§ | âš ï¸ å¯é€‰ | æ–‡æ¡£æåˆ°æ”¯æŒä½†æ— ç¤ºä¾‹,å¯åç»­æ·»åŠ  |

### ğŸ¯ å®æ–½å»ºè®®

1. **ä¼˜å…ˆä½¿ç”¨ apalis å†…ç½®åŠŸèƒ½**
   - é‡è¯•ã€è¶…æ—¶ã€ç›‘æ§ã€ä¼˜é›…å…³é—­ç›´æ¥ä½¿ç”¨ apalis
   - ä¸è¦é‡å¤é€ è½®å­

2. **é‡ç‚¹å®ç°æ ¸å¿ƒä¸šåŠ¡é€»è¾‘**
   - Cron è¡¨è¾¾å¼è§£æå’Œè°ƒåº¦
   - ä»»åŠ¡çº§å¹¶å‘æ§åˆ¶(ä½¿ç”¨ PostgreSQL advisory locks)
   - åŠ¨æ€ä»»åŠ¡ç®¡ç† API

3. **ä»£ç è´¨é‡æå‡**
   - ä½¿ç”¨ apalis åä»£ç é‡å‡å°‘çº¦ 60%
   - æ›´å°‘çš„è‡ªå®šä¹‰ä»£ç æ„å‘³ç€æ›´å°‘çš„ bug
   - åŸºäºæˆç†Ÿåº“,ç¨³å®šæ€§æ›´é«˜

4. **æ€§èƒ½å’Œå¯æ‰©å±•æ€§**
   - apalis çš„ PostgreSQL åç«¯æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²
   - å†…ç½®çš„ Prometheus ç›‘æ§ä¾¿äºæ€§èƒ½è°ƒä¼˜
   - Worker çº§å¹¶å‘æ§åˆ¶ä¿è¯èµ„æºä¸è¢«è€—å°½

### ğŸ“š å‚è€ƒèµ„æº

- [Apalis GitHub](https://github.com/geofmureithi/apalis)
- [Apalis æ–‡æ¡£](https://docs.rs/apalis)
- [Apalis ç¤ºä¾‹](https://github.com/geofmureithi/apalis/tree/main/examples)

